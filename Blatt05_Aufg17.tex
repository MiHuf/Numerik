\subsection*{Aufgabe 17}
Gegeben die symmetrische positiv definite Matrix $A \in \RR^{n \times n}$, ein Vektor
$b \in \RR^n$ und die Funktion
\begin{align}
  \nonumber
  & f : \RR^n \rightarrow \RR \quad \text{mit}\\
  \label{eq-def-f}
  & f(x) = \frac{1}{2} x^T A x - x^T b
\end{align}

\paragraph*{a)}
Zu zeigen: f hat genau ein lokales Minimum $x_*$; dies ist auch ein globales Minimum
und erfüllt $A x_* = b$.

Beweis: \eqref{eq-def-f} lässt sich mit $A = (a_{ij})$ auch schreiben als:
\begin{align}
  \nonumber
  f(x) &=  \frac{1}{2} \sum_{i, j}x_i a_{ij} x_j - \sum_i x_i b_i
  \intertext{damit wird die $k$-te Komponente des Gradienten mit Anwendung der Produktregel:}
  \nonumber
  \nabla_k f(x) &= \frac{\partial}{\partial x_k}f(x) =
  \frac{1}{2}\sum_{i,j}\delta_{ik} a_{ij}x_j+\frac{1}{2}\sum_{i,j}x_i a_{ij}\delta_{jk} - b_k \\
  \label{eq-grad1}
  & =\frac{1}{2}\sum_{j}a_{kj}x_j + \frac{1}{2}\sum_{i} x_i a_{ik} - b_k \;
   \overset{a_{ik} = a_{ki}}{=} \;\sum_{j} a_{kj} x_j - b_k
  \intertext{und für den Gradienten gilt:}
  \label{eq-grad2}
  & \nabla f = A x - b
\end{align}
Die notwendige Bedingung für ein Mininum ist, dass der Gradient an der Stelle $x_*$
verschwindet, also $\nabla f|_{x = x_*} = 0$, und mit \eqref{eq-grad2}:
$ A x_* - b = 0 \; \Rightarrow \;  x_* = A^{-1} b$. Der Ausdruck existiert,
da $A$ als positiv definite Matrix invertierbar ist.

Für die hinreichende Bedingung dass dass $x_*$ ein Minimum ist,
muss noch gezeigt werden, dass die Hesse-Matrix $H$ an dieser Stelle positiv ist:
\begin{align}
  H_f (x) = (h_{ij}(x)) =  \left( \frac{\partial ^2}{\partial x_i \partial x_j}f(x) \right)
  =  \left( \frac{\partial}{\partial x_i}  \right) \nabla_j f(x)
\end{align}
Mit  \eqref{eq-grad1} ergibt sich $h_{ij} = a_{ij}$, also $H = A$ unabhängig von $x$.
Da $A$ positiv definit ist, ist auch $H$ positiv definit, also ist $f$ konvex, d.h.
$f(x) \ge f(x_*) \; \forall x \in \RR^n$ und somit ist $x_*$ globales Minimum.

\paragraph*{b)}

