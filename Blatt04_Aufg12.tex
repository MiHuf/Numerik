\subsection*{Aufgabe 12}
Zu zeigen: Sei $\left<\cdot , \cdot \right>: \KK\times\KK \rightarrow \KK$ ein beliebiges
Skalarprodukt auf $\KK$. Dann gibt es eine positiv definite Matrix $A \in \KK^{n \times n}$,
so dass $\left<x,y\right> = x^* A y$ gilt für alle $x,y \in \KK^n$.

Beweis: Es seien $e_i$ die kanonischen Einheitsvektoren des $\KK^n$, dann lassen
sich $x$ und $y$ schreiben als $x = \sum_{i = 1}^n x_i \cdot e_i$ und
$y = \sum_{j = 1}^n y_j \cdot e_j$ mit $x_i, y_j \in \KK$. Für das Skalarprodukt
gilt dann:
\begin{align*}
  \left<x,y\right> &= \left< \sum_{i = 1}^n x_i \cdot e_i \;,\; \sum_{j = 1}^n y_j \cdot e_j \right> \\
  \intertext{Wegen der Sublinearität des Skalarproduktes im ersten und der Linearität im zweiten Term gilt dafür:}
  \left<x,y\right>  &=  \sum_{i = 1}^n \sum_{j = 1}^n \overline{x_i} \cdot \left<e_i,e_j\right> \cdot  y_j
  =\sum_{i, j = 1}^n  \overline{x_i} \cdot \left<e_i,e_j\right> \cdot y_j\\
  \intertext{Für die gesuchte Matrix $A$ ergibt sich dann:}
  A &= (a_{i,j}) = (\left<e_i,e_j\right>) =
   \begin{pmatrix}
     \left<e_1,e_1\right> & \cdots & \left<e_1,e_n\right>\\
     \vdots & \ddots & \vdots \\
     \left<e_n,e_1\right> & \cdots & \left<e_n,e_n\right>
   \end{pmatrix}
  \\
  \intertext{Das liefert dann:}
  \left<x,y\right>  &=  \overline{(x_1, \cdots, x_n)} \cdot A \cdot
    \begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix} = x^* \cdot A \cdot y
\end{align*}

Es bleibt noch zu zeigen: $A$ ist hermitesch. Aus der Definition des Skalarproduktes
folgt $\left<x,y\right> = (\left<y,x\right>)^*$, also:
\begin{align*}
\left<x,y\right> &= x^* \cdot A \cdot y\\
   &= (\left<y,x\right>)^* = (y^* \cdot A  \cdot x)^* = x^*  \cdot A^*  \cdot (y^*)^*
   = x^* \cdot A^* \cdot y
\end{align*}
Aus dem Vergleich der beiden Gleichungen folgt $A = A^*$, also ist $A$ hermitesch.

Es bleibt noch zu zeigen: $A$ ist positiv definit. Angenommen $A$ hätte einen
Eigenwert $\lambda = 0$ mit dem Eigenvektor $v \ne 0$, dann wäre
$\left<v,v\right> = v^* A v = \lambda v^* v = 0$ im Widerspruch zur Definition
des Skalarpoduktes (muss positiv definit sein).

Es gilt:
\begin{align}
\label{eq-euklid}
  \left<T x,T y\right> &= (T\cdot x)^* \cdot A \cdot T \cdot y
    = x^* \cdot T^* \cdot A \cdot T  \cdot y \eqx   x^* \cdot I \cdot y
    = x^* \cdot y =\left<x, y\right>_\text{Euklid}
\end{align}
Es wird also ein $T$ gesucht, für dass $T^* \cdot A \cdot T = I$ gilt. $A$ ist
hermitesch, positiv definit, und somit diagonalisierbar. Es gibt also eine
unitäre Matrix $U \in \U_n$, so dass gilt:
$U^* \cdot A \cdot U = \diag(\lambda_1, \cdots,\lambda_n) =: D$. Da die Eigenwerte alle
positiv sind, existiert nach dem Satz aus der Vorlesung auch die Matrix $\sqrt{D}$ und
$D^{-1/2} = 1 / \sqrt{D} = \diag\left(\sqrt{1 / \lambda_1}, \cdots, \sqrt{1 /\lambda_n}\right)$
mit den Eigenschaften $D^{-1/2} \cdot D^{-1/2} = \diag(1/\lambda_1, \cdots, 1/ \lambda_n)$
und $D^{-1/2} \cdot D^{-1/2} \cdot D = D^{-1/2} \cdot D \cdot D^{-1/2} = I$. Ein Vergleich
mit \eqref{eq-euklid} liefert dann die gesuchte Abbildung
$T =  D^{-1/2} =  \diag\left(\sqrt{1 / \lambda_1}, \cdots, \sqrt{1 /\lambda_n}\right)$.
Damit wird wegen $D^* = D$ und $T^* =  T$:

\textbf{Jetzt kommt noch Murks, muss ich nochmal nachrechnen!}
\begin{align*}
  \nonumber
  T^* \cdot A \cdot T &= T^* \cdot (U^* \cdot D \cdot U ) \cdot T =
  T^* \cdot U^* \cdot D \cdot U \cdot T
    = (U \cdot T)^* \cdot D \cdot (U \cdot T) \\
  &= \left ( (U \cdot T)^* \cdot D^* \cdot (U \cdot T)^{**}   \right)^* \\
  &= ( U^* \cdot T^* \cdot D^* \cdot T \cdot U )^* = (U^* \cdot I \cdot U)^* = I^* = I
\end{align*}
